<!DOCTYPE html>
<html>
<head>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: auto;
            padding: 20px;
            line-height: 1.6;
            background-color: #f9f9f9;
        }
        h1, h2 {
            text-align: center;
            color: #333;
        }
        blockquote {
            font-style: italic;
            background-color: #fff;
            padding: 10px 15px;
            border-left: 5px solid #ccc;
            margin: 20px 0;
        }
    .back-button {
            display: block;
            margin: 30px auto;
            padding: 10px 20px;
            background-color: #4CAF50;
            color: white;
            border: none;
            cursor: pointer;
            border-radius: 5px;
            font-size: 16px;
        }
        .back-button:hover {
            background-color: #45a049;
        }
    </style>
    
    <title>Context-Aware Bias Detection in News Headlines — README:</title>
</head>
<body>

    <h2><a href="https://www.linkedin.com/in/naimabouri">I'm a curious reader & care about the conversation <i>(This is shared in a personal capacity, outside of working hours.) </i>- N.B - </a> </h2>
    
    
    <h1>Initial Purpose</h1>
    <p>
      This tool helps detect framing patterns in news headlines and summaries in both English and French. Its goal is not to police truth, but to surface how language shapes moral, emotional, and political perception - especially in contexts of conflict, crisis, or injustice.</p>
 <h1>Statement:</h1>
    <p>
      Too often, automated systems mistake emotion for distortion or urgency for bias. This dashboard takes a different approach:
Human suffering is not bias. When a story centers on harm - civilian deaths, famine, medical collapse - we treat that as a humanitarian lens, not manipulation.
Emotionally strong language is not inherently suspect. Terms like “killed,” “bombed,” or “starved” should be evaluated for accuracy and attribution - not penalized for clarity.
Bias detection should not erase the moral weight of events. AI tools must be careful not to “balance” harm out of visibility.    </p>   
  <h1>Meta Bias</h1>
    <p>
      Meta-bias occurs when bias detection systems label morally grounded or factually supported language as biased - especially when describing: Civilian suffering, State violence, Systemic collapse.
This can result in: Erasure of victims, False equivalency in asymmetrical conflicts, Suppression of humanitarian reporting.
 </p>   
  <p>
    Perspective-Aware Principles:
Custom prompt that ensures:
Emotion ≠ manipulation, unless misleading or unsupported.
Strategic framing ≠ bias, if human impact is clearly acknowledged.
“Balance” is not prioritized above truth, context, or harm.  </p>

  <h1>Why? </h1>
    <p>
      <i>This system was trained on patterns from the world -
a world full of brilliance, but also blind spots.</i>
It can predict with astonishing fluency - but it cannot see with care.
This model does not feel the weight of the words it uses.
It does not know who is missing.
It cannot tell you who was silenced before it was trained.
But you can. Leaders in ethical AI <a href="https://www.linkedin.com/in/johnchavens"> - like John C. Havens, among others - </a>  
remind us that responsibility does not begin with the model.
It begins with The ones who choose how, why, and for whom these systems are used.

This model will keep generating.
But the meaning is on us.  </p>   
  
<button class="back-button" onclick="window.location.href='index.html';">
        Back to Main Page
    </button>

<h2>The Power of Fair Narratives:</h2>

    <h2>Inspirational Quotes:</h2>
    <blockquote>
        "The mind is like a parachute — it works best when it's open." - Frank Zappa
    </blockquote>
    <blockquote>
        "Injustice anywhere is a threat to justice everywhere." - Martin Luther King Jr.
    </blockquote>
    <blockquote>
        "We can only see a short distance ahead, but we can see plenty there that needs to be done." - Alan Turing
    </blockquote>

    <h2>Why Fair Narratives Matter</h2>
    <p>
        Fair and balanced narratives shape how societies understand truth, empathy, and responsibility. 
        Policies promoting accurate and inclusive storytelling can reduce bias, improve trust in institutions, 
        and empower communities to engage in constructive dialogue.
    </p>
    <p>According to UNESCO’s <em>Global Media and Information Literacy</em> framework, fostering critical thinking 
        and equitable representation in media is essential for informed decision-making and protecting democratic values.
    </p>
    <p>
        By improving the lens through which readers view the world, we create space for compassion, innovation, 
        and collective progress.
    </p>

    <button class="back-button" onclick="window.location.href='index.html';">
        Back to Main Page
    </button>



</body>
</html>
